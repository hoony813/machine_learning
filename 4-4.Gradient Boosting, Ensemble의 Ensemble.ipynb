{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/imchanghun/Documents/machine_learning'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재 경로 확인\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0   1       1       0       0       0       0       0       0       0       0   \n",
       "1   2       0       0       0       0       0       0       0       1       0   \n",
       "2   3       0       0       0       0       0       0       0       1       0   \n",
       "3   4       1       0       0       1       6       1       5       0       0   \n",
       "4   5       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
       "0  ...        1        0        0        0        0        0        0   \n",
       "1  ...        0        0        0        0        0        0        0   \n",
       "2  ...        0        0        0        0        0        0        0   \n",
       "3  ...        0        1        2        0        0        0        0   \n",
       "4  ...        1        0        0        0        0        1        0   \n",
       "\n",
       "   feat_92  feat_93   target  \n",
       "0        0        0  Class_1  \n",
       "1        0        0  Class_1  \n",
       "2        0        0  Class_1  \n",
       "3        0        0  Class_1  \n",
       "4        0        0  Class_1  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "data = pd.read_csv(\"./data/otto_train.csv\") # product category\n",
    "data.head() # 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nid: 고유 아이디\\nfeat_1 ~ feat_93: 설명변수\\ntarget: 타겟변수 (1~9)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "id: 고유 아이디\n",
    "feat_1 ~ feat_93: 설명변수\n",
    "target: 타겟변수 (1~9)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nCar: 61878  nVar: 95\n"
     ]
    }
   ],
   "source": [
    "nCar = data.shape[0] # 데이터 개수\n",
    "nVar = data.shape[1] # 변수 개수\n",
    "print(\"nCar: %d\" % nCar, \" nVar: %d\" % nVar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의미가 없다고 판단되는 변수 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id'], axis = 1) # id 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 타겟 변수의 문자열을 숫자로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {\"Class_1\": 1,\n",
    "               \"Class_2\": 2,\n",
    "               \"Class_3\": 3,\n",
    "               \"Class_4\": 4,\n",
    "               \"Class_5\": 5,\n",
    "               \"Class_6\": 6,\n",
    "               \"Class_7\": 7,\n",
    "               \"Class_8\": 8,\n",
    "               \"Class_9\": 9}\n",
    "after_mapping_target = data['target'].apply(lambda x: mapping_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설명변수와 타겟변수를 분리, 학습데이터와 평가데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49502, 93) (12376, 93) (49502,) (12376,)\n"
     ]
    }
   ],
   "source": [
    "feature_columns = list(data.columns.difference(['target'])) # target을 제외한 모든 행\n",
    "X = data[feature_columns] # 설명변수\n",
    "y = after_mapping_target # 타겟변수\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state = 42) # 학습데이터와 평가데이터의 비율을 8:2로 분할\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape) # 데이터 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Accuracy: 76.67 %\n",
      "Time: 4.71 seconds\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import time\n",
    "start = time.time() # 시작 시간 지정\n",
    "xgb_dtrain = xgb.DMatrix(data = train_x, label = train_y) # 학습 데이터를 XGBoost 모델에 맞게 변환\n",
    "xgb_dtest = xgb.DMatrix(data = test_x)  # 평가 데이터를 XGBoost 모델에 맞게 변환\n",
    "xgb_param = {\"max_depth\": 10, # 트리 깊이\n",
    "            \"learning_rate\": 0.01, # Step Size\n",
    "            \"n_estimators\": 100, # Number of trees, 트리의 개수\n",
    "            \"objective\": \"multi:softmax\", # 목적 함수\n",
    "            \"num_class\" : len(set(train_y)) + 1} # 파라미터 추가 , Label must be in [0, num_class) -> number_class보다 1 커야한다.\n",
    "xgb_model = xgb.train(params = xgb_param, dtrain = xgb_dtrain) # 학습 진행\n",
    "xgb_model_predict = xgb_model.predict(xgb_dtest) # 평가 데이터 예측\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(test_y, xgb_model_predict) * 100), \"%\") # 정확도 % 계산\n",
    "print(\"Time: %.2f\" % (time.time() - start), \"seconds\") # 코드 실행 시간 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 3., 6., ..., 9., 2., 7.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.0.0-py2.py3-none-macosx_10_13_x86_64.macosx_10_14_x86_64.macosx_10_15_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 829 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn!=0.22.0 in /Users/imchanghun/opt/anaconda3/lib/python3.7/site-packages (from lightgbm) (0.21.3)\n",
      "Requirement already satisfied: numpy in /Users/imchanghun/opt/anaconda3/lib/python3.7/site-packages (from lightgbm) (1.17.2)\n",
      "Requirement already satisfied: scipy in /Users/imchanghun/opt/anaconda3/lib/python3.7/site-packages (from lightgbm) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/imchanghun/opt/anaconda3/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm) (0.13.2)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.0.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/Users/imchanghun/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imchanghun/opt/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3110\n",
      "[LightGBM] [Info] Number of data points in the train set: 49502, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -3.476745\n",
      "[LightGBM] [Info] Start training from score -1.341381\n",
      "[LightGBM] [Info] Start training from score -2.039019\n",
      "[LightGBM] [Info] Start training from score -3.135151\n",
      "[LightGBM] [Info] Start training from score -3.125444\n",
      "[LightGBM] [Info] Start training from score -1.481556\n",
      "[LightGBM] [Info] Start training from score -3.074772\n",
      "[LightGBM] [Info] Start training from score -1.986562\n",
      "[LightGBM] [Info] Start training from score -2.533374\n",
      "Accuracy: 76.28 %\n",
      "Time: 1.83 Seconds\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "start = time.time() # 시작 시간 지정\n",
    "lgb_dtrain = lgb.Dataset(data = train_x, label = train_y) # 학습 데이터를 LigthGBM 모델에 맞게 변환\n",
    "lgb_param = {'max_depth': 10, # 트리 깊이\n",
    "            'learning_rate': 0.01, # Step Size\n",
    "            \"n_estimators\": 100, # Number of trees, 트리 생성 개수\n",
    "            \"objective\": \"multiclass\", # 목적 함수\n",
    "            \"num_class\": len(set(train_y)) + 1} # 파라미터 추가, Label must be in [0,num_class) -> num_class보다 1 커야한다.\n",
    "lgb_model = lgb.train(params=lgb_param, train_set = lgb_dtrain) # 학습 진행\n",
    "lgb_model_predict = np.argmax(lgb_model.predict(test_x), axis=1) # 평가 데이터 예측, Softmax의 결과값 중 가장 큰 값의 Label로 예측\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(test_y, lgb_model_predict) * 100), \"%\") # 정확도 % 계산\n",
    "print(\"Time: %.2f\" % (time.time() - start), \"Seconds\") # 코드 |실행 시간 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.01734061e-15, 2.25081693e-02, 3.62193933e-01, ...,\n",
       "        3.24234521e-02, 5.82126692e-02, 3.67722414e-02],\n",
       "       [1.14084116e-15, 5.36978636e-02, 1.90687128e-01, ...,\n",
       "        3.25081119e-01, 9.38028846e-02, 6.50463131e-02],\n",
       "       [5.94595781e-16, 9.66842220e-03, 5.82817482e-02, ...,\n",
       "        1.42318289e-02, 3.40230275e-02, 2.14919364e-02],\n",
       "       ...,\n",
       "       [7.09105769e-16, 4.63740004e-02, 1.08297559e-01, ...,\n",
       "        5.46934960e-02, 7.24513712e-02, 5.74635996e-01],\n",
       "       [9.88127136e-16, 1.54895684e-02, 5.45515599e-01, ...,\n",
       "        2.45870954e-02, 5.65410617e-02, 3.62344513e-02],\n",
       "       [7.59617500e-16, 1.49480877e-02, 7.44570300e-02, ...,\n",
       "        5.76695793e-01, 1.43227106e-01, 2.74567219e-02]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-0.24.1-cp37-none-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (11.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.4 MB 711 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plotly\n",
      "  Downloading plotly-4.11.0-py2.py3-none-any.whl (13.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.1 MB 8.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /Users/imchanghun/opt/anaconda3/lib/python3.7/site-packages (from catboost) (1.17.2)\n",
      "Requirement already satisfied: six in /Users/imchanghun/opt/anaconda3/lib/python3.7/site-packages (from catboost) (1.12.0)\n",
      "Requirement already satisfied: matplotlib in /Users/imchanghun/opt/anaconda3/lib/python3.7/site-packages (from catboost) (3.1.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /Users/imchanghun/opt/anaconda3/lib/python3.7/site-packages (from catboost) (0.25.1)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.14.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: scipy in /Users/imchanghun/opt/anaconda3/lib/python3.7/site-packages (from catboost) (1.3.1)\n",
      "Collecting retrying>=1.3.3\n",
      "  Using cached retrying-1.3.3.tar.gz (10 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/imchanghun/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/imchanghun/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->catboost) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/imchanghun/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->catboost) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/imchanghun/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->catboost) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/imchanghun/opt/anaconda3/lib/python3.7/site-packages (from pandas>=0.24.0->catboost) (2019.3)\n",
      "Requirement already satisfied: setuptools in /Users/imchanghun/opt/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (41.4.0)\n",
      "Building wheels for collected packages: retrying\n",
      "  Building wheel for retrying (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11429 sha256=f2fe1ace109f79fb2a6739e8270dc289c14a7b520cf55e6fc12e354a6c75e930\n",
      "  Stored in directory: /Users/imchanghun/Library/Caches/pip/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
      "Successfully built retrying\n",
      "Installing collected packages: retrying, plotly, graphviz, catboost\n",
      "Successfully installed catboost-0.24.1 graphviz-0.14.1 plotly-4.11.0 retrying-1.3.3\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/Users/imchanghun/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5907034\ttotal: 360ms\tremaining: 35.6s\n",
      "1:\tlearn: 0.6356107\ttotal: 594ms\tremaining: 29.1s\n",
      "2:\tlearn: 0.6411256\ttotal: 906ms\tremaining: 29.3s\n",
      "3:\tlearn: 0.6480344\ttotal: 1.16s\tremaining: 27.8s\n",
      "4:\tlearn: 0.6508222\ttotal: 1.44s\tremaining: 27.4s\n",
      "5:\tlearn: 0.6499939\ttotal: 1.76s\tremaining: 27.6s\n",
      "6:\tlearn: 0.6507818\ttotal: 2.11s\tremaining: 28.1s\n",
      "7:\tlearn: 0.6548422\ttotal: 2.51s\tremaining: 28.9s\n",
      "8:\tlearn: 0.6559533\ttotal: 2.84s\tremaining: 28.7s\n",
      "9:\tlearn: 0.6560947\ttotal: 3.27s\tremaining: 29.5s\n",
      "10:\tlearn: 0.6568421\ttotal: 3.55s\tremaining: 28.7s\n",
      "11:\tlearn: 0.6588219\ttotal: 3.88s\tremaining: 28.4s\n",
      "12:\tlearn: 0.6592259\ttotal: 4.16s\tremaining: 27.8s\n",
      "13:\tlearn: 0.6611248\ttotal: 4.64s\tremaining: 28.5s\n",
      "14:\tlearn: 0.6625591\ttotal: 4.98s\tremaining: 28.2s\n",
      "15:\tlearn: 0.6631853\ttotal: 5.42s\tremaining: 28.5s\n",
      "16:\tlearn: 0.6639328\ttotal: 5.71s\tremaining: 27.9s\n",
      "17:\tlearn: 0.6668821\ttotal: 6.01s\tremaining: 27.4s\n",
      "18:\tlearn: 0.6669630\ttotal: 6.41s\tremaining: 27.3s\n",
      "19:\tlearn: 0.6675286\ttotal: 6.78s\tremaining: 27.1s\n",
      "20:\tlearn: 0.6673266\ttotal: 7.08s\tremaining: 26.6s\n",
      "21:\tlearn: 0.6677104\ttotal: 7.45s\tremaining: 26.4s\n",
      "22:\tlearn: 0.6682558\ttotal: 7.78s\tremaining: 26s\n",
      "23:\tlearn: 0.6683972\ttotal: 8.06s\tremaining: 25.5s\n",
      "24:\tlearn: 0.6686599\ttotal: 8.35s\tremaining: 25.1s\n",
      "25:\tlearn: 0.6681952\ttotal: 8.63s\tremaining: 24.6s\n",
      "26:\tlearn: 0.6684982\ttotal: 8.88s\tremaining: 24s\n",
      "27:\tlearn: 0.6692053\ttotal: 9.2s\tremaining: 23.7s\n",
      "28:\tlearn: 0.6696699\ttotal: 9.47s\tremaining: 23.2s\n",
      "29:\tlearn: 0.6699325\ttotal: 9.72s\tremaining: 22.7s\n",
      "30:\tlearn: 0.6705992\ttotal: 10s\tremaining: 22.3s\n",
      "31:\tlearn: 0.6709426\ttotal: 10.3s\tremaining: 21.9s\n",
      "32:\tlearn: 0.6708012\ttotal: 10.6s\tremaining: 21.5s\n",
      "33:\tlearn: 0.6709426\ttotal: 10.9s\tremaining: 21.1s\n",
      "34:\tlearn: 0.6707002\ttotal: 11.2s\tremaining: 20.7s\n",
      "35:\tlearn: 0.6715082\ttotal: 11.4s\tremaining: 20.3s\n",
      "36:\tlearn: 0.6705992\ttotal: 11.7s\tremaining: 19.9s\n",
      "37:\tlearn: 0.6725991\ttotal: 12s\tremaining: 19.6s\n",
      "38:\tlearn: 0.6729829\ttotal: 12.3s\tremaining: 19.3s\n",
      "39:\tlearn: 0.6725991\ttotal: 12.6s\tremaining: 18.9s\n",
      "40:\tlearn: 0.6734273\ttotal: 12.9s\tremaining: 18.5s\n",
      "41:\tlearn: 0.6738314\ttotal: 13.2s\tremaining: 18.2s\n",
      "42:\tlearn: 0.6741546\ttotal: 13.5s\tremaining: 17.9s\n",
      "43:\tlearn: 0.6739728\ttotal: 13.7s\tremaining: 17.5s\n",
      "44:\tlearn: 0.6741950\ttotal: 14s\tremaining: 17.1s\n",
      "45:\tlearn: 0.6750636\ttotal: 14.3s\tremaining: 16.8s\n",
      "46:\tlearn: 0.6758919\ttotal: 14.6s\tremaining: 16.5s\n",
      "47:\tlearn: 0.6757707\ttotal: 14.9s\tremaining: 16.2s\n",
      "48:\tlearn: 0.6762151\ttotal: 15.2s\tremaining: 15.8s\n",
      "49:\tlearn: 0.6774474\ttotal: 15.5s\tremaining: 15.5s\n",
      "50:\tlearn: 0.6777100\ttotal: 15.8s\tremaining: 15.2s\n",
      "51:\tlearn: 0.6786594\ttotal: 16.1s\tremaining: 14.8s\n",
      "52:\tlearn: 0.6789827\ttotal: 16.4s\tremaining: 14.5s\n",
      "53:\tlearn: 0.6804372\ttotal: 16.7s\tremaining: 14.2s\n",
      "54:\tlearn: 0.6804372\ttotal: 16.9s\tremaining: 13.9s\n",
      "55:\tlearn: 0.6809220\ttotal: 17.2s\tremaining: 13.5s\n",
      "56:\tlearn: 0.6812250\ttotal: 17.5s\tremaining: 13.2s\n",
      "57:\tlearn: 0.6813058\ttotal: 17.8s\tremaining: 12.9s\n",
      "58:\tlearn: 0.6811846\ttotal: 18.1s\tremaining: 12.5s\n",
      "59:\tlearn: 0.6813260\ttotal: 18.4s\tremaining: 12.3s\n",
      "60:\tlearn: 0.6816694\ttotal: 18.7s\tremaining: 11.9s\n",
      "61:\tlearn: 0.6823159\ttotal: 18.9s\tremaining: 11.6s\n",
      "62:\tlearn: 0.6832653\ttotal: 19.2s\tremaining: 11.3s\n",
      "63:\tlearn: 0.6840734\ttotal: 19.5s\tremaining: 11s\n",
      "64:\tlearn: 0.6840734\ttotal: 19.8s\tremaining: 10.7s\n",
      "65:\tlearn: 0.6846592\ttotal: 20.1s\tremaining: 10.4s\n",
      "66:\tlearn: 0.6843360\ttotal: 20.4s\tremaining: 10s\n",
      "67:\tlearn: 0.6846390\ttotal: 20.7s\tremaining: 9.74s\n",
      "68:\tlearn: 0.6854269\ttotal: 21s\tremaining: 9.42s\n",
      "69:\tlearn: 0.6858309\ttotal: 21.3s\tremaining: 9.12s\n",
      "70:\tlearn: 0.6858309\ttotal: 21.6s\tremaining: 8.81s\n",
      "71:\tlearn: 0.6865783\ttotal: 21.8s\tremaining: 8.49s\n",
      "72:\tlearn: 0.6864167\ttotal: 22.2s\tremaining: 8.21s\n",
      "73:\tlearn: 0.6868611\ttotal: 22.5s\tremaining: 7.89s\n",
      "74:\tlearn: 0.6869217\ttotal: 22.8s\tremaining: 7.58s\n",
      "75:\tlearn: 0.6870429\ttotal: 23.1s\tremaining: 7.28s\n",
      "76:\tlearn: 0.6875278\ttotal: 23.4s\tremaining: 6.98s\n",
      "77:\tlearn: 0.6881136\ttotal: 23.6s\tremaining: 6.66s\n",
      "78:\tlearn: 0.6883762\ttotal: 23.9s\tremaining: 6.37s\n",
      "79:\tlearn: 0.6888207\ttotal: 24.2s\tremaining: 6.06s\n",
      "80:\tlearn: 0.6892449\ttotal: 24.5s\tremaining: 5.75s\n",
      "81:\tlearn: 0.6898509\ttotal: 24.8s\tremaining: 5.45s\n",
      "82:\tlearn: 0.6897095\ttotal: 25.1s\tremaining: 5.14s\n",
      "83:\tlearn: 0.6902549\ttotal: 25.4s\tremaining: 4.84s\n",
      "84:\tlearn: 0.6909822\ttotal: 25.7s\tremaining: 4.53s\n",
      "85:\tlearn: 0.6910832\ttotal: 26s\tremaining: 4.23s\n",
      "86:\tlearn: 0.6914468\ttotal: 26.3s\tremaining: 3.92s\n",
      "87:\tlearn: 0.6916084\ttotal: 26.6s\tremaining: 3.62s\n",
      "88:\tlearn: 0.6919922\ttotal: 26.9s\tremaining: 3.32s\n",
      "89:\tlearn: 0.6925579\ttotal: 27.2s\tremaining: 3.02s\n",
      "90:\tlearn: 0.6928407\ttotal: 27.5s\tremaining: 2.72s\n",
      "91:\tlearn: 0.6930427\ttotal: 27.8s\tremaining: 2.42s\n",
      "92:\tlearn: 0.6935073\ttotal: 28.1s\tremaining: 2.11s\n",
      "93:\tlearn: 0.6940932\ttotal: 28.4s\tremaining: 1.81s\n",
      "94:\tlearn: 0.6944972\ttotal: 28.7s\tremaining: 1.51s\n",
      "95:\tlearn: 0.6948810\ttotal: 28.9s\tremaining: 1.21s\n",
      "96:\tlearn: 0.6951840\ttotal: 29.2s\tremaining: 904ms\n",
      "97:\tlearn: 0.6954264\ttotal: 29.6s\tremaining: 604ms\n",
      "98:\tlearn: 0.6955881\ttotal: 29.9s\tremaining: 302ms\n",
      "99:\tlearn: 0.6956285\ttotal: 30.2s\tremaining: 0us\n",
      "Accuracy: 69.64 %\n",
      "Time: 30.31 seconds\n"
     ]
    }
   ],
   "source": [
    "import catboost as cb\n",
    "start = time.time() # 시작 시간 지정\n",
    "cb_dtrain = cb.Pool(data = train_x, label = train_y) # 학습 데이터를 Catboost 모델에 맞게 변환\n",
    "cb_param = {\"max_depth\": 10, # 트리 깊이\n",
    "           \"learning_rate\": 0.01, # Step Size\n",
    "           \"n_estimators\": 100, # Number of trees, 트리 생성 개수\n",
    "           \"eval_metric\": \"Accuracy\", # 평가 척도\n",
    "           \"loss_function\": \"MultiClass\"} # 손실 함수, 목적 함수\n",
    "cb_model = cb.train(pool = cb_dtrain, params = cb_param) # 학습 진행\n",
    "cb_model_predict = np.argmax(cb_model.predict(test_x), axis = 1) + 1 # 평가 데이터 예측, Softmax의 결과값 중 가장 큰 값의 Label로 예측, 인덱스의 순서를 맞추기 위해 +1\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(test_y, cb_model_predict) * 100), \"%\") # 정확도 % rPtks\n",
    "print(\"Time: %.2f\" % (time.time() - start), \"seconds\") # 코드 실행 시간 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35426047,  1.22109587,  0.44230101, ..., -0.1698448 ,\n",
       "        -0.02059177, -0.2130643 ],\n",
       "       [-0.07235138,  0.42535181,  0.20060428, ...,  0.21863604,\n",
       "         0.2719157 ,  0.25089315],\n",
       "       [-0.3315885 , -0.31862353, -0.31279765, ..., -0.29798357,\n",
       "        -0.24018767, -0.32984969],\n",
       "       ...,\n",
       "       [ 0.05304325,  0.02500267, -0.14752573, ..., -0.20741963,\n",
       "         0.12789417,  1.51166757],\n",
       "       [-0.55093666,  1.7691278 ,  0.99746884, ..., -0.3420542 ,\n",
       "        -0.49799871, -0.38136323],\n",
       "       [-0.3033724 ,  0.09352675, -0.11808658, ...,  0.65825036,\n",
       "         1.05515787, -0.20799899]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  floors  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00     1.0   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25     2.0   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00     1.0   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00     1.0   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00     1.0   \n",
       "\n",
       "   waterfront  condition  grade  yr_built  yr_renovated  zipcode      lat  \\\n",
       "0           0          3      7      1955             0    98178  47.5112   \n",
       "1           0          3      7      1951          1991    98125  47.7210   \n",
       "2           0          3      6      1933             0    98028  47.7379   \n",
       "3           0          5      7      1965             0    98136  47.5208   \n",
       "4           0          3      8      1987             0    98074  47.6168   \n",
       "\n",
       "      long  \n",
       "0 -122.257  \n",
       "1 -122.319  \n",
       "2 -122.233  \n",
       "3 -122.393  \n",
       "4 -122.045  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "data = pd.read_csv(\"./data/kc_house_data.csv\")\n",
    "data.head() # 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id','date','zipcode','lat','long'], axis= 1) # id, date, zipcode, lat, long 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15129, 8) (6484, 8) (15129,) (6484,)\n"
     ]
    }
   ],
   "source": [
    "feature_columns = list(data.columns.difference(['price']))\n",
    "X = data[feature_columns]\n",
    "y = data['price']\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42) # 학습데이터와 평가데이터의 비율을 7:3\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape) # 데이터 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 237\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 537729.263666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "lgb_dtrain = lgb.Dataset(data = train_x, label = train_y) # 학습 데이터를 LightGBM 모델에 맞게 변환\n",
    "lgb_param = {'max_depth': 10, # 트리 깊이\n",
    "            \"learning_rate\": 0.01, # Step Size\n",
    "            \"n_estimators\": 500, # Number of trees, 트리 생성 개수\n",
    "            'objective': 'regression'} # 파라미터 추가, Label must be in [0, num_class) -> num_class보다 1 커야한다.\n",
    "lgb_model = lgb.train(params = lgb_param, train_set = lgb_dtrain) # 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210904.17249451784"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "sqrt(mean_squared_error(lgb_model.predict(test_x),test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble의 Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9538\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 232\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 541371.137550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imchanghun/opt/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9528\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 228\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 535918.010906\n",
      "9567\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 235\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 543280.162602\n",
      "9688\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 233\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 538976.934034\n",
      "9581\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 230\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 533291.663824\n",
      "9600\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 237\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 544440.096107\n",
      "9541\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 235\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 537436.086721\n",
      "9516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 234\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 536218.788353\n",
      "9614\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 230\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 535654.132329\n",
      "9530\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 236\n",
      "[LightGBM] [Info] Number of data points in the train set: 15129, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 541194.641219\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "bagging_predict_result = [] # 빈 리스트 생성\n",
    "for _ in range(10):\n",
    "    data_index = [data_index for data_index in range(train_x.shape[0])] # 학습 데이터의 인덱스를 리스트로 변환\n",
    "    random_data_index = np.random.choice(data_index, train_x.shape[0]) # 데이터의 1/10 크기만큼 랜덤 샘플링, //는 소수점을 무시하기 위함\n",
    "    print(len(set(random_data_index)))\n",
    "    lgb_dtrain = lgb.Dataset(data = train_x.iloc[random_data_index,], label = train_y.iloc[random_data_index,]) # 학습 데이터를 LightGBM 모델에 맞게 변환\n",
    "    lgb_param = {'max_depth': 14, # 트리 깊이\n",
    "                'learning_rate': 0.01, # Step Size\n",
    "                 'n_estimators': 500, # Number of trees, 트리 생성 개수\n",
    "                 'objective': 'regression'} # 파라미터 추가, Label must be in [0, num_class) -> num_class보다 1 커야한다\n",
    "    lgb_model = lgb.train(params=lgb_param, train_set = lgb_dtrain) # 학습 진행\n",
    "    predict1 = lgb_model.predict(test_x) # 테스트 데이터 예측\n",
    "    bagging_predict_result.append(predict1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([502255.88524611, 668654.8345624 , 891936.81934501, ...,\n",
       "        336425.72652745, 865785.06542248, 459020.31273736]),\n",
       " array([521103.37136853, 626580.69405982, 933027.50351642, ...,\n",
       "        337612.50292701, 850386.40091157, 451720.48973972]),\n",
       " array([508237.08598847, 661298.37697849, 971284.39841148, ...,\n",
       "        361992.26813021, 896544.53520603, 465507.50957056]),\n",
       " array([497321.56268039, 597943.05301243, 984751.04583033, ...,\n",
       "        347505.67268301, 969788.88281171, 456599.85711046]),\n",
       " array([ 479535.87497738,  598943.66054933, 1008738.94579951, ...,\n",
       "         333284.36390326,  964171.75657004,  482462.60616543]),\n",
       " array([507819.69787987, 634143.6932939 , 967154.84726532, ...,\n",
       "        333348.83636334, 891392.05275484, 475397.70274258]),\n",
       " array([507415.91418662, 647563.11029373, 978704.7969378 , ...,\n",
       "        342272.33044608, 891408.97329989, 463173.21573961]),\n",
       " array([521227.14228919, 633994.51441139, 984911.79169643, ...,\n",
       "        330756.55576194, 880439.54657869, 472348.3633022 ]),\n",
       " array([520917.27832303, 610446.58418315, 914544.88089509, ...,\n",
       "        333338.99833371, 974997.48994869, 462600.67706642]),\n",
       " array([525637.19483347, 652756.35434746, 931686.17685244, ...,\n",
       "        341156.03890133, 920064.2594592 , 468149.31305383])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging을 바탕으로 예측한 결과값에 대한 평균을 계산\n",
    "bagging_predict = [] # 빈 리스트 생성\n",
    "for lst2_index in range(test_x.shape[0]): # 테스트 데이터 개수만큼의 반복\n",
    "    temp_predict = [] # 임시 빈 리스트 생성 (반복문 내 결과값 저장)\n",
    "    for lst_index in range(len(bagging_predict_result)):  # Bagging 결과 리스트 반복\n",
    "        temp_predict.append(bagging_predict_result[lst_index][lst2_index]) # 각 Bagging 결과 예측한 값 중 같은 인덱스를 리스트에 저장\n",
    "    bagging_predict.append(np.mean(temp_predict)) # 해당 인덱스의 30개의 결과값에 대한 평균을 최종 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 210682.699009588\n"
     ]
    }
   ],
   "source": [
    "# 예측한 결과값들의 평균을 계산하여 실제 테스트 데이터의 타겟변수와 비교하여 성능 평가\n",
    "\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(bagging_predict, test_y)))) # RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[509147.1007773053,\n",
       " 633232.4875692094,\n",
       " 956674.1206549844,\n",
       " 1643963.8795113303,\n",
       " 644435.0893324817,\n",
       " 368328.28812954423,\n",
       " 696320.9292997416,\n",
       " 435851.3671626147,\n",
       " 462703.8790795698,\n",
       " 488839.1152137094,\n",
       " 631678.5839093649,\n",
       " 392210.80990142433,\n",
       " 301444.5792662418,\n",
       " 358317.1669741544,\n",
       " 338410.8506648115,\n",
       " 1313422.36679262,\n",
       " 357143.5096889053,\n",
       " 1022856.2881740012,\n",
       " 318749.62461327895,\n",
       " 522173.15029920964,\n",
       " 375742.25705323403,\n",
       " 1843315.2454337825,\n",
       " 663868.4833597793,\n",
       " 538751.9279366222,\n",
       " 504819.27282307856,\n",
       " 487723.03219143173,\n",
       " 299261.9705630215,\n",
       " 257205.21647815648,\n",
       " 480939.14672892186,\n",
       " 539223.5184532373,\n",
       " 487047.38749407337,\n",
       " 476615.8365943123,\n",
       " 459335.88381398114,\n",
       " 574702.2681337569,\n",
       " 378111.99166699185,\n",
       " 1035833.541072169,\n",
       " 889128.5620355582,\n",
       " 520636.4078182505,\n",
       " 355566.60268343793,\n",
       " 1495381.9438899937,\n",
       " 396307.9718521495,\n",
       " 274978.5195188256,\n",
       " 513058.2040646197,\n",
       " 340129.182571915,\n",
       " 255089.7265422743,\n",
       " 243355.63448639648,\n",
       " 329983.6280255836,\n",
       " 332404.8044288701,\n",
       " 353518.71809674177,\n",
       " 560727.0583029825,\n",
       " 370089.49980356114,\n",
       " 341686.2349040565,\n",
       " 765884.614476313,\n",
       " 337141.1353774142,\n",
       " 465310.2169985765,\n",
       " 1589377.6408798709,\n",
       " 475706.8684548892,\n",
       " 709039.5745833284,\n",
       " 327933.08447268215,\n",
       " 656480.2295668202,\n",
       " 484601.36542285106,\n",
       " 374236.63644942775,\n",
       " 299042.48729761585,\n",
       " 519535.5952017352,\n",
       " 448429.90876579506,\n",
       " 282436.7671927184,\n",
       " 381156.2719024459,\n",
       " 1606287.7502517807,\n",
       " 478831.18832534103,\n",
       " 666293.9798917769,\n",
       " 443413.13244197966,\n",
       " 301033.6349075675,\n",
       " 761595.517909251,\n",
       " 519526.7904531696,\n",
       " 502689.1494654108,\n",
       " 1316487.0039749276,\n",
       " 815002.1907395509,\n",
       " 287855.71341225074,\n",
       " 456660.4821657493,\n",
       " 935428.2100263869,\n",
       " 642622.6747039785,\n",
       " 376157.7770235944,\n",
       " 669299.3088017754,\n",
       " 359550.50356482447,\n",
       " 815658.225736946,\n",
       " 529757.7181671393,\n",
       " 517053.38348662807,\n",
       " 558051.3264928323,\n",
       " 357883.47722814867,\n",
       " 468458.45634157164,\n",
       " 347637.01120221213,\n",
       " 400851.40618531697,\n",
       " 628332.9050925294,\n",
       " 1051188.0920502474,\n",
       " 431219.3763394856,\n",
       " 490810.6599552341,\n",
       " 360265.61169171013,\n",
       " 312364.20512548473,\n",
       " 817915.0084476669,\n",
       " 461352.4738232639,\n",
       " 257679.1346346783,\n",
       " 913072.5213762533,\n",
       " 989233.6037589641,\n",
       " 477587.58290670096,\n",
       " 1070321.3905362503,\n",
       " 299799.9324012233,\n",
       " 488361.71552420396,\n",
       " 483429.3711136755,\n",
       " 808196.9732559538,\n",
       " 2342217.183094957,\n",
       " 551363.182000458,\n",
       " 320847.15702668007,\n",
       " 557169.7320481545,\n",
       " 624895.094856178,\n",
       " 552219.5588658828,\n",
       " 337053.447629253,\n",
       " 313875.74905849807,\n",
       " 256058.74128140105,\n",
       " 320407.1129489703,\n",
       " 338410.8506648115,\n",
       " 383136.3176632036,\n",
       " 284729.40744834376,\n",
       " 348138.64837122615,\n",
       " 258188.43236056654,\n",
       " 592473.5726998884,\n",
       " 653535.6014080178,\n",
       " 275295.01852837607,\n",
       " 740703.949878656,\n",
       " 456909.14471483964,\n",
       " 423819.30084070563,\n",
       " 529645.1646466572,\n",
       " 463727.64765889465,\n",
       " 412617.9390834335,\n",
       " 833415.9453549883,\n",
       " 376362.45422713,\n",
       " 461363.3253093682,\n",
       " 381295.47841952473,\n",
       " 354880.3867287254,\n",
       " 919057.5865343038,\n",
       " 622103.0032975161,\n",
       " 524960.2979678486,\n",
       " 783705.2100740538,\n",
       " 893392.7308289433,\n",
       " 406369.6483336609,\n",
       " 259839.81788898812,\n",
       " 383940.2687561013,\n",
       " 484005.3054108225,\n",
       " 248567.78772642836,\n",
       " 412409.54536089324,\n",
       " 471778.82291432365,\n",
       " 566655.3124589755,\n",
       " 688605.3381682464,\n",
       " 537767.6196289081,\n",
       " 1099582.5782863852,\n",
       " 931965.4833089246,\n",
       " 873538.1719047574,\n",
       " 597805.0024150095,\n",
       " 658116.6291791514,\n",
       " 582616.5555736892,\n",
       " 486587.30631364154,\n",
       " 648860.5571124388,\n",
       " 367960.460149818,\n",
       " 332404.8044288701,\n",
       " 356227.4438961317,\n",
       " 362415.63748175727,\n",
       " 349379.92915755074,\n",
       " 299152.71208766405,\n",
       " 313952.9711935465,\n",
       " 454062.06090775307,\n",
       " 465415.03474228625,\n",
       " 629935.6685566118,\n",
       " 390847.7550718928,\n",
       " 468851.26345353667,\n",
       " 593285.0599069234,\n",
       " 424055.97923316044,\n",
       " 422552.3598562571,\n",
       " 353576.5372856767,\n",
       " 687105.8507157703,\n",
       " 347153.4699703149,\n",
       " 256308.6844369821,\n",
       " 314541.679589765,\n",
       " 483900.95948428067,\n",
       " 534286.7476346006,\n",
       " 674109.3970713031,\n",
       " 476987.5299688329,\n",
       " 469174.1186332508,\n",
       " 272207.8805870457,\n",
       " 437659.4693057401,\n",
       " 349590.6038157864,\n",
       " 350912.7124029591,\n",
       " 373576.7966135221,\n",
       " 659297.9093486024,\n",
       " 1557201.377882003,\n",
       " 1331826.6743949386,\n",
       " 268411.8497381389,\n",
       " 481931.22547526716,\n",
       " 493805.26821393624,\n",
       " 1584111.0659767536,\n",
       " 469684.5095512442,\n",
       " 465339.1667937506,\n",
       " 320980.56334467063,\n",
       " 384212.8704399894,\n",
       " 517930.32545902923,\n",
       " 782779.7453100274,\n",
       " 788492.5560733236,\n",
       " 311460.306330218,\n",
       " 504819.27282307856,\n",
       " 307309.07133794413,\n",
       " 509477.84897648834,\n",
       " 1340295.3361893035,\n",
       " 360265.61169171013,\n",
       " 420895.1272862464,\n",
       " 459569.9875292328,\n",
       " 360265.61169171013,\n",
       " 333558.77646454924,\n",
       " 697255.2823474047,\n",
       " 795751.1805651551,\n",
       " 346816.4935348166,\n",
       " 357838.9352429762,\n",
       " 362672.5940338292,\n",
       " 1703303.584498578,\n",
       " 540926.9164333352,\n",
       " 503319.08531542716,\n",
       " 459482.25445325795,\n",
       " 528825.3004503765,\n",
       " 734178.6158638939,\n",
       " 343016.47551786364,\n",
       " 1295235.116827594,\n",
       " 885764.0872506663,\n",
       " 462738.68582130887,\n",
       " 358628.1812333982,\n",
       " 478923.48908288695,\n",
       " 701862.9236601231,\n",
       " 300540.05049931107,\n",
       " 345339.67711875075,\n",
       " 384687.53835874016,\n",
       " 353625.0634096518,\n",
       " 350625.0777437162,\n",
       " 2379157.2420458095,\n",
       " 349205.7974188495,\n",
       " 442373.78272297594,\n",
       " 461114.8116428098,\n",
       " 592291.6737427749,\n",
       " 406738.4628821138,\n",
       " 470580.9813687353,\n",
       " 312059.44459367066,\n",
       " 519198.93261384126,\n",
       " 552071.2554962102,\n",
       " 718740.6064451787,\n",
       " 866463.125639132,\n",
       " 522858.7254037883,\n",
       " 439808.4165950248,\n",
       " 723575.5359783722,\n",
       " 351338.3254548179,\n",
       " 350912.7124029591,\n",
       " 529623.5014888959,\n",
       " 501364.93980302045,\n",
       " 471047.48564174597,\n",
       " 884008.3149218736,\n",
       " 369153.52926845395,\n",
       " 3181739.914697238,\n",
       " 636453.6141685226,\n",
       " 754461.3562499076,\n",
       " 1067915.3138718805,\n",
       " 506502.4905152523,\n",
       " 678124.0589241717,\n",
       " 925766.5034314636,\n",
       " 349619.68503478833,\n",
       " 727831.1366680837,\n",
       " 427199.26585636317,\n",
       " 469788.65484161756,\n",
       " 340635.7792694077,\n",
       " 285164.85972203984,\n",
       " 435267.01516970235,\n",
       " 416919.2455891837,\n",
       " 1388891.1856712648,\n",
       " 306807.95346865436,\n",
       " 346113.41305086704,\n",
       " 521563.7946641719,\n",
       " 365060.991932246,\n",
       " 317630.1802844758,\n",
       " 501976.96674807277,\n",
       " 366445.4307653834,\n",
       " 445609.14445048216,\n",
       " 482365.2276899376,\n",
       " 454162.93770907,\n",
       " 368996.13218254305,\n",
       " 640709.7369163589,\n",
       " 354636.0767577228,\n",
       " 317024.9611871572,\n",
       " 786150.8614225691,\n",
       " 453310.7933354323,\n",
       " 259541.59144076696,\n",
       " 346645.73394634074,\n",
       " 659297.9093486024,\n",
       " 654874.1853593359,\n",
       " 484489.5959133954,\n",
       " 450581.09120103176,\n",
       " 456588.6195810077,\n",
       " 569040.0851177428,\n",
       " 471502.62661915924,\n",
       " 545696.0987653012,\n",
       " 328749.7290059789,\n",
       " 569374.5566352099,\n",
       " 342274.2393045668,\n",
       " 838144.2477363518,\n",
       " 454062.06090775307,\n",
       " 391429.2017066224,\n",
       " 331850.05888152483,\n",
       " 327234.6495975746,\n",
       " 364937.8679334456,\n",
       " 291248.3741154279,\n",
       " 837691.5523487356,\n",
       " 1660223.9900206667,\n",
       " 944885.1594300804,\n",
       " 446909.30413863517,\n",
       " 820025.6053599495,\n",
       " 477098.6793430224,\n",
       " 799261.6313728818,\n",
       " 348758.75354589685,\n",
       " 398146.4471630921,\n",
       " 493042.3438752916,\n",
       " 268411.8497381389,\n",
       " 300275.7159237936,\n",
       " 459921.7227843539,\n",
       " 465415.03474228625,\n",
       " 581573.2891478555,\n",
       " 301145.25501163094,\n",
       " 506309.9251553646,\n",
       " 258188.43236056654,\n",
       " 666363.1260954265,\n",
       " 296230.4194651487,\n",
       " 503017.42046463426,\n",
       " 303101.4282068796,\n",
       " 389495.88081028266,\n",
       " 482594.4934467707,\n",
       " 614650.5008220765,\n",
       " 472372.9040134919,\n",
       " 919446.0838604281,\n",
       " 261762.41334108583,\n",
       " 1778963.019707853,\n",
       " 471833.0693700486,\n",
       " 440939.96123607596,\n",
       " 567016.1254724206,\n",
       " 679241.9622376893,\n",
       " 625066.1920514381,\n",
       " 341283.2994532309,\n",
       " 460723.26645898074,\n",
       " 483195.8063957627,\n",
       " 721194.555324074,\n",
       " 284314.6242549332,\n",
       " 361772.9242491063,\n",
       " 478795.303850754,\n",
       " 617964.0595944508,\n",
       " 337545.7531203482,\n",
       " 861493.9681172915,\n",
       " 554667.2439227488,\n",
       " 914860.0881308636,\n",
       " 1006772.6770485211,\n",
       " 641333.6130380111,\n",
       " 369153.52926845395,\n",
       " 794618.3460931029,\n",
       " 355571.88585882355,\n",
       " 561967.9825140728,\n",
       " 681079.5916432671,\n",
       " 326572.1285626573,\n",
       " 783944.4031635209,\n",
       " 403915.6866223487,\n",
       " 978237.7863592643,\n",
       " 383391.9362890172,\n",
       " 497423.55618822866,\n",
       " 679217.7769621778,\n",
       " 555857.3233865355,\n",
       " 352178.43610116956,\n",
       " 547398.0466929993,\n",
       " 376561.09652316466,\n",
       " 337110.90912769287,\n",
       " 540076.872531107,\n",
       " 390717.20428245043,\n",
       " 417627.4923748161,\n",
       " 371360.3596374159,\n",
       " 727120.8935292617,\n",
       " 631168.8636735227,\n",
       " 440620.42706644797,\n",
       " 462107.3163436529,\n",
       " 460832.4086006388,\n",
       " 300731.6998284344,\n",
       " 499602.8950132664,\n",
       " 425115.0598399737,\n",
       " 465254.4152444913,\n",
       " 557170.2601381766,\n",
       " 394208.6236704457,\n",
       " 379723.12732604495,\n",
       " 403635.497837552,\n",
       " 1417851.4243993484,\n",
       " 383391.9362890172,\n",
       " 348229.8884367045,\n",
       " 1178945.9996651947,\n",
       " 664097.630710924,\n",
       " 382291.88057357643,\n",
       " 443413.13244197966,\n",
       " 481820.301956823,\n",
       " 658734.2757035124,\n",
       " 458566.36723292654,\n",
       " 395954.9372101324,\n",
       " 442854.5407054348,\n",
       " 465415.03474228625,\n",
       " 423819.30084070563,\n",
       " 479715.1507456893,\n",
       " 469174.1186332508,\n",
       " 351706.20303999167,\n",
       " 472045.9590481951,\n",
       " 622978.9872228903,\n",
       " 422171.4519662753,\n",
       " 270260.5565885804,\n",
       " 380299.23146138835,\n",
       " 462983.733230403,\n",
       " 452190.54546498245,\n",
       " 1095508.368401028,\n",
       " 457444.39763993147,\n",
       " 390505.9032151436,\n",
       " 567736.4005147119,\n",
       " 331536.71760326234,\n",
       " 664633.4185699208,\n",
       " 407659.8028950393,\n",
       " 476181.1823024759,\n",
       " 480338.4978093266,\n",
       " 492340.3320848119,\n",
       " 554555.974042661,\n",
       " 334242.34113836556,\n",
       " 609933.6099895418,\n",
       " 515280.18857471214,\n",
       " 685074.1095092199,\n",
       " 533833.3577556073,\n",
       " 504570.4035325553,\n",
       " 573514.5516805216,\n",
       " 521088.56630679604,\n",
       " 380280.76414798124,\n",
       " 364913.79355571873,\n",
       " 351136.4336300859,\n",
       " 650258.5785175341,\n",
       " 379288.51757195365,\n",
       " 362380.2786057867,\n",
       " 274575.3752807224,\n",
       " 370099.0979836689,\n",
       " 384181.4249235666,\n",
       " 833415.9453549883,\n",
       " 2385766.48374368,\n",
       " 443403.8067709189,\n",
       " 1143773.929805604,\n",
       " 500860.40609244874,\n",
       " 268038.05405247025,\n",
       " 485709.36084463046,\n",
       " 452963.85463828297,\n",
       " 427290.98153933586,\n",
       " 684740.1848817201,\n",
       " 381921.7861077339,\n",
       " 825649.8210062014,\n",
       " 371441.7644324717,\n",
       " 275652.9867262718,\n",
       " 469530.21905568556,\n",
       " 641792.3147597038,\n",
       " 998876.486852216,\n",
       " 374589.8474300747,\n",
       " 721550.5247363179,\n",
       " 457775.003359846,\n",
       " 354900.9915396898,\n",
       " 544425.8794060501,\n",
       " 965973.0889890365,\n",
       " 430637.2174931186,\n",
       " 472372.9040134919,\n",
       " 351706.20303999167,\n",
       " 457941.7134453537,\n",
       " 1258458.7523736716,\n",
       " 446498.5063300834,\n",
       " 488980.5773321476,\n",
       " 386954.7156597338,\n",
       " 464755.82150765805,\n",
       " 318699.7048906653,\n",
       " 452480.32673403557,\n",
       " 303848.75989745324,\n",
       " 334127.7403298882,\n",
       " 344075.31670638185,\n",
       " 389056.3760668421,\n",
       " 453114.3589264591,\n",
       " 637095.3565892256,\n",
       " 508435.87235025706,\n",
       " 333207.89830806165,\n",
       " 758327.8477356129,\n",
       " 645704.0363167934,\n",
       " 721246.0667974183,\n",
       " 348001.6396779154,\n",
       " 424055.97923316044,\n",
       " 660046.7130345679,\n",
       " 1906668.1935687724,\n",
       " 490892.26847456786,\n",
       " 686214.884577987,\n",
       " 367677.49856679013,\n",
       " 371807.2257326427,\n",
       " 342315.93885134574,\n",
       " 687571.186389022,\n",
       " 484601.36542285106,\n",
       " 321142.9532961216,\n",
       " 521098.22205249127,\n",
       " 349019.9118132903,\n",
       " 565479.697057867,\n",
       " 792827.7578535526,\n",
       " 1049830.6224062606,\n",
       " 331897.2499296229,\n",
       " 537285.6275186095,\n",
       " 1180967.4236313899,\n",
       " 465415.03474228625,\n",
       " 809712.1502337132,\n",
       " 629917.071177063,\n",
       " 461785.661734444,\n",
       " 801605.7243016054,\n",
       " 704087.9903450878,\n",
       " 253641.3955767656,\n",
       " 374236.63644942775,\n",
       " 282188.11558066297,\n",
       " 438982.8183147505,\n",
       " 521409.01310509804,\n",
       " 338350.0380814826,\n",
       " 488916.79869793804,\n",
       " 541703.4393781885,\n",
       " 414729.0992127452,\n",
       " 501986.5387606075,\n",
       " 356047.9952116228,\n",
       " 834964.4294148667,\n",
       " 341785.68558812235,\n",
       " 373052.58356357215,\n",
       " 381453.976116695,\n",
       " 1196114.2587338893,\n",
       " 462142.123085392,\n",
       " 298906.54755951854,\n",
       " 281942.66955702216,\n",
       " 473992.01895147143,\n",
       " 827390.9515531306,\n",
       " 471639.51545159647,\n",
       " 663786.7407549868,\n",
       " 535607.8392467253,\n",
       " 450856.3311238099,\n",
       " 1004470.0315712614,\n",
       " 283645.9987023011,\n",
       " 967854.0622130946,\n",
       " 641638.8352512212,\n",
       " 516888.0594323444,\n",
       " 1100844.0510256593,\n",
       " 466559.00835249136,\n",
       " 284117.84762264986,\n",
       " 845752.2478324575,\n",
       " 341744.4858269155,\n",
       " 633440.3215153863,\n",
       " 1529505.051838977,\n",
       " 349619.3308027776,\n",
       " 497015.5124765254,\n",
       " 453016.7192052131,\n",
       " 368741.0243313489,\n",
       " 255231.55453372616,\n",
       " 844791.393557126,\n",
       " 433425.7289885261,\n",
       " 300651.5970569953,\n",
       " 475719.39217620913,\n",
       " 356035.1955622204,\n",
       " 295913.3726379314,\n",
       " 489676.1682176815,\n",
       " 355603.1851772164,\n",
       " 411944.07910466933,\n",
       " 388678.08180689585,\n",
       " 479774.4771154012,\n",
       " 488093.6149370322,\n",
       " 539155.0716008407,\n",
       " 783953.9977652518,\n",
       " 332479.116975913,\n",
       " 326387.62925879366,\n",
       " 379288.51757195365,\n",
       " 384212.8704399894,\n",
       " 326912.1779393647,\n",
       " 413945.49379946414,\n",
       " 769170.0502134452,\n",
       " 498953.34273144713,\n",
       " 859330.7090816877,\n",
       " 825154.1947190525,\n",
       " 483878.39052149525,\n",
       " 444129.75091649796,\n",
       " 474713.7936867263,\n",
       " 316631.42493281653,\n",
       " 400974.87551071076,\n",
       " 443475.7619286225,\n",
       " 314427.6142993692,\n",
       " 477200.46228377504,\n",
       " 663786.7407549868,\n",
       " 430236.44062111696,\n",
       " 411348.8555487398,\n",
       " 469637.9347502932,\n",
       " 410947.17167977325,\n",
       " 1009750.7593807962,\n",
       " 909595.5246759607,\n",
       " 745324.4631413186,\n",
       " 368823.74936036376,\n",
       " 460832.4086006388,\n",
       " 400074.0994434763,\n",
       " 572127.9804707111,\n",
       " 273598.72088766366,\n",
       " 384143.24222294113,\n",
       " 355429.44329683686,\n",
       " 315819.9489765835,\n",
       " 355776.1365526061,\n",
       " 283398.20900761965,\n",
       " 409629.6970492125,\n",
       " 593970.6113836092,\n",
       " 311721.7109768834,\n",
       " 444240.90398350963,\n",
       " 508898.80647201755,\n",
       " 486220.3674674585,\n",
       " 353763.37264410796,\n",
       " 333300.3253515585,\n",
       " 283084.4677411624,\n",
       " 539737.3066066524,\n",
       " 473854.4846398183,\n",
       " 1707968.9752173484,\n",
       " 461785.661734444,\n",
       " 2124590.6893176315,\n",
       " 675924.1186330437,\n",
       " 1022732.104975687,\n",
       " 610322.1004341518,\n",
       " 421548.3917139463,\n",
       " 455253.54007416003,\n",
       " 968027.7200131012,\n",
       " 698201.2418725681,\n",
       " 479698.84495297994,\n",
       " 469181.53319851606,\n",
       " 747026.5836043356,\n",
       " 507679.22476311616,\n",
       " 383568.81413755723,\n",
       " 398883.4150427169,\n",
       " 363983.8365911191,\n",
       " 469016.7215473399,\n",
       " 338833.23847277614,\n",
       " 749110.5630358711,\n",
       " 506701.00977581425,\n",
       " 794618.3460931029,\n",
       " 683839.945350396,\n",
       " 507579.4625207308,\n",
       " 449792.14072437334,\n",
       " 496230.8438346534,\n",
       " 486474.2633664321,\n",
       " 510628.30436191865,\n",
       " 578102.8701623518,\n",
       " 311995.13581968495,\n",
       " 1049804.3002505905,\n",
       " 313546.4346346136,\n",
       " 572746.4492612565,\n",
       " 275104.9151034751,\n",
       " 1695741.2125063676,\n",
       " 843492.0694708202,\n",
       " 631787.1141462979,\n",
       " 506141.0592608601,\n",
       " 642402.3586482536,\n",
       " 556083.9526186174,\n",
       " 349057.5384369496,\n",
       " 526054.1670465351,\n",
       " 467329.40365876106,\n",
       " 1008178.3654092711,\n",
       " 373409.03274723917,\n",
       " 516097.2514354653,\n",
       " 986328.2891196331,\n",
       " 527710.7190520952,\n",
       " 461693.7351261858,\n",
       " 452225.7232997051,\n",
       " 1081252.0915563088,\n",
       " 320510.12758547516,\n",
       " 636461.1985056525,\n",
       " 788686.9691218471,\n",
       " 320510.12758547516,\n",
       " 629507.8784809278,\n",
       " 596514.944922717,\n",
       " 407831.56222436216,\n",
       " 472950.5126067547,\n",
       " 612325.9723790525,\n",
       " 432073.2607927563,\n",
       " 348001.6396779154,\n",
       " 536206.6212030498,\n",
       " 275104.9151034751,\n",
       " 346037.06911337335,\n",
       " 469248.39944075036,\n",
       " 540492.5273887523,\n",
       " 442891.7894231874,\n",
       " 829515.3906378627,\n",
       " 413073.55805061886,\n",
       " 301444.5792662418,\n",
       " 321271.1800522504,\n",
       " 469174.1186332508,\n",
       " 744055.7165927908,\n",
       " 761359.9395961476,\n",
       " 369153.52926845395,\n",
       " 313280.47027720086,\n",
       " 386155.67406361207,\n",
       " 273508.16062578274,\n",
       " 857072.687070713,\n",
       " 401094.44544052694,\n",
       " 285884.3785668657,\n",
       " 337832.77425849775,\n",
       " 492992.1081768281,\n",
       " 498426.78085355833,\n",
       " 469174.1186332508,\n",
       " 1177015.5701494871,\n",
       " 1022331.023450451,\n",
       " 1175386.056341699,\n",
       " 438915.7692145199,\n",
       " 579254.4158183103,\n",
       " 367937.25699981296,\n",
       " 507838.45467588137,\n",
       " 357356.53972296196,\n",
       " 394221.9865625928,\n",
       " 345636.94429540297,\n",
       " 814999.283113248,\n",
       " 465310.2169985765,\n",
       " 349163.80847280374,\n",
       " 395188.21078619076,\n",
       " 293359.9916567288,\n",
       " 535673.6135015003,\n",
       " 491388.5562418167,\n",
       " 425889.60600561637,\n",
       " 527141.5368948163,\n",
       " 279941.880375878,\n",
       " 639742.3427679898,\n",
       " 527756.3637887392,\n",
       " 456660.4821657493,\n",
       " 471502.62661915924,\n",
       " 300814.9090072046,\n",
       " 360265.61169171013,\n",
       " 1177490.694978341,\n",
       " 780994.669296485,\n",
       " 444187.7156282882,\n",
       " 320276.6937637358,\n",
       " 351060.0745288461,\n",
       " 1018281.4119943405,\n",
       " 541095.7199036895,\n",
       " 427298.0709084881,\n",
       " 275483.1953374402,\n",
       " 381131.7275801311,\n",
       " 294147.3332345826,\n",
       " 825946.8298216235,\n",
       " 255032.03517772965,\n",
       " 320694.6155537997,\n",
       " 299307.6925293326,\n",
       " 470580.9813687353,\n",
       " 473425.6969734001,\n",
       " 598280.4222195761,\n",
       " 577658.9867958453,\n",
       " 386099.5727188793,\n",
       " 479084.2646450853,\n",
       " 554607.4774006332,\n",
       " 478708.9358964952,\n",
       " 471135.1529430475,\n",
       " 622103.0032975161,\n",
       " 508112.6071957286,\n",
       " 775003.8309348368,\n",
       " 387298.2071900439,\n",
       " 314751.07800416154,\n",
       " 468251.9779938827,\n",
       " 589527.6223212859,\n",
       " 471587.217597924,\n",
       " 493309.5840478417,\n",
       " 930566.8855494491,\n",
       " 530114.6017310573,\n",
       " 732628.0821822941,\n",
       " 635514.3224054558,\n",
       " 818240.8226918433,\n",
       " 275385.5822062662,\n",
       " 469132.8614385229,\n",
       " 469580.69480182946,\n",
       " 837404.4164334765,\n",
       " 895579.2355390933,\n",
       " 278540.6634173136,\n",
       " 259839.81788898812,\n",
       " 493544.30297829304,\n",
       " 295628.0848307029,\n",
       " 699238.3454167855,\n",
       " 389791.8315571957,\n",
       " 479618.45289527084,\n",
       " 514316.7971306525,\n",
       " 382436.1996390743,\n",
       " 299307.6925293326,\n",
       " 293507.0768335853,\n",
       " 328363.0182336295,\n",
       " 638310.3199298875,\n",
       " 283198.2881363513,\n",
       " 371449.1695544213,\n",
       " 472192.205240093,\n",
       " 386307.8561161655,\n",
       " 521088.56630679604,\n",
       " 370490.7420104405,\n",
       " 394221.9865625928,\n",
       " 465310.2169985765,\n",
       " 354151.39847348473,\n",
       " 1180231.238212277,\n",
       " 617737.6763994757,\n",
       " 333430.32925040077,\n",
       " 461184.8915211495,\n",
       " 748806.76241377,\n",
       " 642118.832553639,\n",
       " 276045.70996177464,\n",
       " 468360.00044862565,\n",
       " 389495.88081028266,\n",
       " 300554.166774555,\n",
       " 869290.648012439,\n",
       " 475874.86758654565,\n",
       " 555001.8222187477,\n",
       " 493357.8910354332,\n",
       " 679954.4514929376,\n",
       " 585749.5167071286,\n",
       " 860187.9821225007,\n",
       " 666293.9798917769,\n",
       " 790565.3677374728,\n",
       " 380359.9725164822,\n",
       " 1041295.2523416359,\n",
       " 616300.2586901746,\n",
       " 806056.722674808,\n",
       " 469199.2622258732,\n",
       " 473134.9982342369,\n",
       " 381921.7861077339,\n",
       " 465310.2169985765,\n",
       " 374236.63644942775,\n",
       " 783705.2100740538,\n",
       " 519831.4660943638,\n",
       " 485188.2206543245,\n",
       " 279328.26147555263,\n",
       " 275104.9151034751,\n",
       " 301467.6058876828,\n",
       " 804563.166456116,\n",
       " 656480.2295668202,\n",
       " 458503.28448742174,\n",
       " 361299.69448926154,\n",
       " 470151.04852652765,\n",
       " 364937.8679334456,\n",
       " 657198.0133617321,\n",
       " 275328.8912151088,\n",
       " 652037.7756200895,\n",
       " 524357.0457674761,\n",
       " 354898.944604256,\n",
       " 276567.41194823186,\n",
       " 478831.18832534103,\n",
       " 506744.3275088583,\n",
       " 376643.3304702907,\n",
       " 688070.0212002245,\n",
       " 334127.7403298882,\n",
       " 389791.8315571957,\n",
       " 530350.7148374723,\n",
       " 303026.74953843147,\n",
       " 558950.9187718241,\n",
       " 687529.5730688485,\n",
       " 697897.0337880941,\n",
       " 488165.93340818444,\n",
       " 420454.71089374134,\n",
       " 687094.088607934,\n",
       " 514770.8589019198,\n",
       " 656480.2295668202,\n",
       " 1576613.78021341,\n",
       " 555960.3844347738,\n",
       " 345056.0563034633,\n",
       " 703849.3026671609,\n",
       " 835092.1718760432,\n",
       " 339712.09792097704,\n",
       " 408986.3241561059,\n",
       " 376157.7770235944,\n",
       " 293580.51437170827,\n",
       " 508952.6630777473,\n",
       " 504085.57910567184,\n",
       " 403727.98813127895,\n",
       " 491646.40156949684,\n",
       " 332541.51451431087,\n",
       " 370698.62571260706,\n",
       " 255397.9098069611,\n",
       " 354880.3867287254,\n",
       " 348229.8884367045,\n",
       " 330764.8880472953,\n",
       " 344726.3452622863,\n",
       " 332600.58248378785,\n",
       " 806138.6848964146,\n",
       " 417542.7467230683,\n",
       " 438619.54561734694,\n",
       " 712468.3172356457,\n",
       " 355434.2488740039,\n",
       " 255032.03517772965,\n",
       " 371245.73490097834,\n",
       " 302294.4452864195,\n",
       " 587754.5357533013,\n",
       " 302063.8717189516,\n",
       " 515829.1700314818,\n",
       " 812351.6833779997,\n",
       " 580973.7630196136,\n",
       " 561657.8351515697,\n",
       " 508099.97399734927,\n",
       " 266828.6579144761,\n",
       " 896901.1983857611,\n",
       " 644435.0893324817,\n",
       " 866463.125639132,\n",
       " 328994.11582686147,\n",
       " 464343.5170530456,\n",
       " 791842.249126375,\n",
       " 521465.87840371515,\n",
       " 256198.14905133573,\n",
       " 1230470.2240303827,\n",
       " 314492.14605536876,\n",
       " 640577.5050863136,\n",
       " 475719.39217620913,\n",
       " 751876.8553520921,\n",
       " 556735.3342409048,\n",
       " 457775.003359846,\n",
       " 460832.4086006388,\n",
       " 446659.7018379665,\n",
       " 552868.5159890809,\n",
       " 1353592.1409514828,\n",
       " 482348.7851545073,\n",
       " 833433.1924079319,\n",
       " 486522.9800338,\n",
       " 379035.8618774562,\n",
       " 274607.93515629886,\n",
       " 438886.2013279571,\n",
       " 546777.7621663965,\n",
       " 485376.9207551562,\n",
       " 455143.8587964663,\n",
       " 294147.3332345826,\n",
       " 364414.7147392903,\n",
       " 349466.3035188816,\n",
       " 504544.4991055131,\n",
       " 557796.510586448,\n",
       " 282436.7671927184,\n",
       " 382674.01558851154,\n",
       " 507567.26991638,\n",
       " 629507.8784809278,\n",
       " 990193.0003305018,\n",
       " 667501.3464671804,\n",
       " 360453.2093366095,\n",
       " 776974.763902544,\n",
       " 711111.1344683376,\n",
       " 857914.7637096622,\n",
       " 355959.317338954,\n",
       " 2307796.473421787,\n",
       " 368103.1144779001,\n",
       " 381043.82317056914,\n",
       " 499582.1266509771,\n",
       " 331484.96240704355,\n",
       " 351874.02024151455,\n",
       " 561727.1355987923,\n",
       " 663912.8869085894,\n",
       " 699370.8652366454,\n",
       " 275001.3907400964,\n",
       " 352178.43610116956,\n",
       " 551048.8730378139,\n",
       " 2354488.2392365714,\n",
       " 555337.9780560326,\n",
       " 468765.1346818727,\n",
       " 928900.7162604558,\n",
       " 627788.0458971068,\n",
       " 553731.3530858293,\n",
       " 786828.9137721689,\n",
       " 748103.9471827393,\n",
       " 457775.003359846,\n",
       " 297947.02935550536,\n",
       " 431437.942112778,\n",
       " 674892.9791435258,\n",
       " 557967.8977702891,\n",
       " 285103.80392386334,\n",
       " 300554.166774555,\n",
       " 558522.3624995177,\n",
       " 408376.47230946616,\n",
       " 683431.1732490634,\n",
       " 501514.53776122816,\n",
       " 975807.1565654464,\n",
       " 380612.1506634221,\n",
       " 292556.17663536087,\n",
       " 387667.3679174612,\n",
       " 288293.69017622,\n",
       " 360265.61169171013,\n",
       " 339712.09792097704,\n",
       " 397913.2007907638,\n",
       " 911942.7052650896,\n",
       " 574951.7383381877,\n",
       " 366115.6979714917,\n",
       " 512776.99502688815,\n",
       " 654558.0923941412,\n",
       " 256463.15866114706,\n",
       " 525068.4748966001,\n",
       " 368928.8425633382,\n",
       " 646842.1534858921,\n",
       " 643061.1723236425,\n",
       " 464192.2041280006,\n",
       " 285932.42188076396,\n",
       " 436550.996183019,\n",
       " 351271.02591672,\n",
       " 871557.5061380111,\n",
       " 359378.68890150555,\n",
       " 571180.5858324869,\n",
       " 419637.44447319396,\n",
       " 386954.7156597338,\n",
       " 353671.437525486,\n",
       " 346365.38373467245,\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
